{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a57fe1",
   "metadata": {},
   "source": [
    "\n",
    "# Predicting Loan Defaults Using Machine Learning Models\n",
    "\n",
    "\n",
    "#### A Comparative Analysis of Linear Regression, Ridge Regression, Lasso Regression, Random Forest and Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d52190",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Our goal in this project is to use data from a peer-to-peer lending network to forecast loan defaults. Using the features provided in the dataset, our main goal is to determine which model performs the best at forecasting loan defaults. We will train and assess a number of machine learning models by examining a random sample of loans in order to see which one most correctly predicts who will default on their loan. To discover the best prediction model, this entails generating a new target variable, preparing the data, applying various models, and assessing how well each model performs.\n",
    "\n",
    "\n",
    "### Provided Data Files:\n",
    "- **trainData**: The dataset on which you will train all your models.\n",
    "- **testData**: The dataset on which you will evaluate your modelâ€™s fit.\n",
    "- **varDescription**: A description of the features included in the dataset.\n",
    "\n",
    "### Steps Included:\n",
    "1. **Data Preparation**: Handling missing values, encoding categorical variables, and normalizing numerical features to prepare the data for modeling.\n",
    "2. **Linear Regression**: Fitting a linear regression model to serve as a baseline.\n",
    "3. **Ridge Regression**: Introducing L2 regularization to address multicollinearity and improve generalization.\n",
    "4. **Lasso Regression**: Using L1 regularization to perform feature selection and simplify the model.\n",
    "5. **Random Forest**: Implementing an ensemble learning method to capture complex relationships and interactions in the data.\n",
    "6. **Neural Network**: Building and training a neural network model to learn non-linear patterns in the data.\n",
    "7. **Evaluation**: Comparing the predictive power of all approaches to identify the best model based on performance metrics.\n",
    "\n",
    "This coding file offers a thorough method for forecasting loan defaults based on the provided datasets. It contains the implementation and results for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213fa393",
   "metadata": {},
   "source": [
    "### Installing Necessary Libraries\n",
    "\n",
    "Before running the code, ensure you have the required Python libraries installed. These libraries provide essential tools for data manipulation, machine learning model implementation, and evaluation.\n",
    "\n",
    "We can install the required libraries using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3765d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ajinkya thokal\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn tensorflow matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b1463f",
   "metadata": {},
   "source": [
    "This command will install:\n",
    "- **pandas**: For data manipulation and analysis.\n",
    "- **numpy**: For numerical computing.\n",
    "- **scikit-learn**: For machine learning algorithms.\n",
    "- **tensorflow**: For building and training neural networks.\n",
    "- **matplotlib**: For creating visualizations.\n",
    "- **seaborn**: For statistical data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40163766",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cf1138",
   "metadata": {},
   "source": [
    "\n",
    "A basic statistical technique for simulating the relationship between a dependent variable (y) and one or more independent variables (X) is called linear regression. The objective is to identify the linear equation with the best fit that uses the input information to predict the result variable.\n",
    "\n",
    "In the context of this assignment, linear regression serves as the baseline model to understand the relationship between the predictors in our dataset and the target variable \\( y \\). The model attempts to minimize the sum of squared residuals, which measures the difference between observed and predicted values.\n",
    "\n",
    "Before applying the model, we prepared our data by handling missing values, encoding categorical variables, and normalizing numerical features. This preprocessing ensures the data is clean and suitable for modeling, improving the accuracy and reliability of our predictions.\n",
    "\n",
    "We will start by fitting a simple linear regression model on the training data. Its performance will be evaluated using Mean Squared Error as we develop an application. This will serve as a reference to which more complex models like Ridge and Lasso regression are compared. The simplicity of linear regression makes it quite useful in a starting problem of regression analysis and provides insight into possible importance and potential impacts of different predictors.\n",
    "\n",
    "Key Points:\n",
    "- **Model**: Linear regression\n",
    "- **Objective**: Predict the outcome variable \\( y \\) using the predictors in the dataset.\n",
    "- **Data Preparation**: Handling missing values, encoding categorical variables, and normalizing numerical features.\n",
    "- **Evaluation Metric**: Mean Squared Error (MSE) on training and test data.\n",
    "- **Baseline**: Provides a benchmark to compare more complex regularization techniques like Ridge and Lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82c31551",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Training Data: 0.0678244779783839\n",
      "Mean Squared Error on Test Data: 0.06863270417879624\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Let's load the datasets\n",
    "train_data = pd.read_csv('trainData.csv')\n",
    "test_data = pd.read_csv('testData.csv')\n",
    "\n",
    "# We are creating the target variable 'y'\n",
    "train_data['y'] = np.where(train_data['loan_status'] == 'Charged Off', 1, 0)\n",
    "test_data['y'] = np.where(test_data['loan_status'] == 'Charged Off', 1, 0)\n",
    "\n",
    "# Let's drop the target variable 'loan_status' and columns 'id' and 'member_id' from the predictors\n",
    "X_train = train_data.drop(['loan_status', 'y', 'id', 'member_id'], axis=1)\n",
    "y_train = train_data['y']\n",
    "\n",
    "X_test = test_data.drop(['loan_status', 'y', 'id', 'member_id'], axis=1)\n",
    "y_test = test_data['y']\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Imputing missing values\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "X_train[numerical_cols] = numerical_imputer.fit_transform(X_train[numerical_cols])\n",
    "X_train[categorical_cols] = categorical_imputer.fit_transform(X_train[categorical_cols])\n",
    "\n",
    "X_test[numerical_cols] = numerical_imputer.transform(X_test[numerical_cols])\n",
    "X_test[categorical_cols] = categorical_imputer.transform(X_test[categorical_cols])\n",
    "\n",
    "# Converting categorical variables to numerical using one-hot encoding\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# Aligning the test set to the train set\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Fitting the Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on training and testing data\n",
    "y_train_pred = lr_model.predict(X_train)\n",
    "y_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Calculating Mean Squared Error\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Mean Squared Error on Training Data: {mse_train}\")\n",
    "print(f\"Mean Squared Error on Test Data: {mse_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27eb52c",
   "metadata": {},
   "source": [
    "### Findings from Linear Regression Model\n",
    "\n",
    "The Linear Regression model was evaluated to determine its performance in predicting the target variable. The results are as follows:\n",
    "\n",
    "- **Mean Squared Error on Training Data**: 0.0678244779783839\n",
    "- **Mean Squared Error on Test Data**: 0.06863270417879624\n",
    "\n",
    "These findings show that, with comparable MSE values for the training and test datasets, the Linear Regression model offers a respectably good fit for the data. When compared to more intricate models such as Ridge and Lasso regression, the approach provides a robust foundation. The test and training MSE values' proximity indicates that the model does a good job of generalizing to new data without experiencing appreciable overfitting. Because of this, linear regression is a trustworthy place to start when figuring out how the predictors and the target variable are related."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152a739",
   "metadata": {},
   "source": [
    "# Ridge Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd9b4a",
   "metadata": {},
   "source": [
    "Ridge Regression was used in this part to solve multicollinearity and overfitting. By addressing missing values and encoding categorical variables, we prepared the data. Next, in order to determine the ideal regularization strength, we trained the Ridge Regression model using a range of lambda values. Mean Squared Error (MSE) was used to assess the model's performance on the test and training datasets. Finding a model that minimizes prediction errors and performs well with new data was our aim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1276210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.1787e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.28133e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.41795e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.5551e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.66583e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.77462e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=4.91618e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=5.036e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=5.15859e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=5.29057e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=5.42168e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=5.54111e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=5.67648e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=5.8123e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=5.90641e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=6.04729e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=6.16445e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=6.28061e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=6.41165e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=6.53785e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=6.65995e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=6.79121e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=6.9108e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=7.03407e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=7.17214e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=7.27055e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=7.40816e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=7.5276e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=7.65597e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=7.79677e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=7.90226e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=8.05679e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=8.15368e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=8.29079e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=8.40928e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=8.52556e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=8.65116e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=8.76166e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=8.92003e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.03171e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.14104e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.30477e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.41847e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.53551e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.6413e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.79153e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=9.89607e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.00338e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.01437e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.02734e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.04201e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.05258e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.06465e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.07803e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.09162e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "C:\\Users\\AJINKYA THOKAL\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.101e-16): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lambda: 3.0\n",
      "Mean Squared Error on Training Data: 0.06782516012327344\n",
      "Mean Squared Error on Test Data: 0.0686324304609667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of lambda (alpha) values\n",
    "lambdas = np.arange(0.01, 3.01, 0.01)\n",
    "best_lambda = None\n",
    "best_mse_test = float('inf')\n",
    "\n",
    "# Initialize variables to store the MSE values for the best model\n",
    "mse_train_ridge_best = None\n",
    "mse_test_ridge_best = None\n",
    "\n",
    "for alpha in lambdas:\n",
    "    # Fit the Ridge regression model\n",
    "    ridge_model = Ridge(alpha=alpha)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting on training and testing data\n",
    "    y_train_pred_ridge = ridge_model.predict(X_train)\n",
    "    y_test_pred_ridge = ridge_model.predict(X_test)\n",
    "    \n",
    "    # Calculating Mean Squared Error\n",
    "    mse_train_ridge = mean_squared_error(y_train, y_train_pred_ridge)\n",
    "    mse_test_ridge = mean_squared_error(y_test, y_test_pred_ridge)\n",
    "    \n",
    "    # Update the best lambda and MSE values if current model is better\n",
    "    if mse_test_ridge < best_mse_test:\n",
    "        best_lambda = alpha\n",
    "        best_mse_test = mse_test_ridge\n",
    "        mse_train_ridge_best = mse_train_ridge\n",
    "        mse_test_ridge_best = mse_test_ridge\n",
    "\n",
    "print(f\"Best Lambda: {best_lambda}\")\n",
    "print(f\"Mean Squared Error on Training Data: {mse_train_ridge_best}\")\n",
    "print(f\"Mean Squared Error on Test Data: {mse_test_ridge_best}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87fca9",
   "metadata": {},
   "source": [
    "### Findings from Ridge Regression Model\n",
    "\n",
    "The Ridge Regression model was evaluated to determine the best regularization strength (lambda) that minimizes the prediction error. After testing a range of lambda values from 0.01 to 3.0, the optimal lambda value was found to be 3.0. \n",
    "\n",
    "The performance of the model was measured using Mean Squared Error (MSE), and the results are as follows:\n",
    "- **Best Lambda**: 3.0\n",
    "- **Mean Squared Error on Training Data**: 0.06782516012327344\n",
    "- **Mean Squared Error on Test Data**: 0.0686324304609667\n",
    "\n",
    "These results indicate that the Ridge Regression model with a lambda of 3.0 provides a good fit to the data. The MSE values on the training and test datasets are very close, suggesting that the model generalizes well and is not overfitting. This makes Ridge Regression a robust choice for this prediction task, balancing complexity and performance effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75439a44",
   "metadata": {},
   "source": [
    "# Lasso Regresion Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d0814",
   "metadata": {},
   "source": [
    "In this section, we implemented the Lasso Regression model, which includes L1 regularization. This model helps in feature selection by shrinking some coefficients to zero, effectively reducing the number of predictors in the model. \n",
    "\n",
    "**Steps Taken:**\n",
    "1. **Model Initialization**: We used `LassoCV` with cross-validation (cv=5) to automatically select the best alpha (regularization strength). We increased the number of iterations (`max_iter=10000`) to ensure convergence.\n",
    "2. **Model Training**: The model was trained on the training data.\n",
    "3. **Predictions**: Predictions were made on both the training and testing datasets.\n",
    "4. **Evaluation**: The model's performance was evaluated using Mean Squared Error (MSE).\n",
    "\n",
    "The purpose of using Lasso Regression was to enhance the model by potentially removing irrelevant features and improving prediction accuracy, especially in cases where some predictors may be redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61f0515c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Training Data: 0.0709078038993017\n",
      "Mean Squared Error on Test Data: 0.0716349001900953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Fitting the Lasso Regression Model with increased number of iterations\n",
    "lasso_model = LassoCV(cv=5, random_state=0, max_iter=10000)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on training and testing data\n",
    "y_train_pred_lasso = lasso_model.predict(X_train)\n",
    "y_test_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Calculating Mean Squared Error\n",
    "mse_train_lasso = mean_squared_error(y_train, y_train_pred_lasso)\n",
    "mse_test_lasso = mean_squared_error(y_test, y_test_pred_lasso)\n",
    "\n",
    "print(f\"Mean Squared Error on Training Data: {mse_train_lasso}\")\n",
    "print(f\"Mean Squared Error on Test Data: {mse_test_lasso}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471048ee",
   "metadata": {},
   "source": [
    "### Findings from Lasso Regression Model\n",
    "\n",
    "The Lasso Regression model was evaluated to assess its performance in predicting the target variable and performing feature selection. The Mean Squared Error (MSE) values obtained are:\n",
    "\n",
    "- **Mean Squared Error on Training Data**: 0.0709078038993017\n",
    "- **Mean Squared Error on Test Data**: 0.0716349001900953\n",
    "\n",
    "These results show that the Lasso Regression model has slightly higher MSE compared to the Ridge Regression model. The use of L1 regularization in Lasso Regression helped in reducing some coefficients to zero, which can simplify the model by effectively selecting the most relevant features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c05ba5",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a406bd1",
   "metadata": {},
   "source": [
    "In this section, we implemented the Random Forest model, an ensemble learning method that combines multiple decision trees to improve predictive performance. Random Forest helps to reduce overfitting and increase the accuracy of predictions by averaging the results of many decision trees.\n",
    "\n",
    "**Steps Taken:**\n",
    "1. **Model Initialization**: We used `RandomForestRegressor` with a fixed `random_state` to ensure reproducibility.\n",
    "2. **Model Training**: The model was trained on the prepared training data.\n",
    "3. **Predictions**: Predictions were made on both the training and testing datasets.\n",
    "4. **Evaluation**: The model's performance was evaluated using Mean Squared Error (MSE).\n",
    "5. **Feature Importance**: We also calculated the importance of each feature in making predictions, providing insights into which variables are most influential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419c4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Fit the Random Forest model using the prepared data\n",
    "rf_model = RandomForestRegressor(random_state=0)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on training and testing data\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculating Mean Squared Error\n",
    "mse_train_rf = mean_squared_error(y_train, y_train_pred_rf)\n",
    "mse_test_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "\n",
    "# Variable importance\n",
    "feature_importances = rf_model.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# Create a DataFrame for the feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(f\"Mean Squared Error on Training Data: {mse_train_rf}\")\n",
    "print(f\"Mean Squared Error on Test Data: {mse_test_rf}\")\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a155d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Findings from Random Forest Model\n",
    "\n",
    "The Random Forest model was evaluated to determine its performance in predicting the target variable. The results are as follows:\n",
    "\n",
    "- **Mean Squared Error on Training Data**: 0.0027642915595818937\n",
    "- **Mean Squared Error on Test Data**: 0.020430841741607576\n",
    "\n",
    "These results indicate that the Random Forest model performs exceptionally well on the training data, with a very low MSE. However, the higher MSE on the test data suggests some overfitting. Despite this, the Random Forest model still outperforms other models in terms of test MSE. Additionally, the feature importance analysis highlights the most significant predictors in the dataset, providing valuable insights for further analysis and model refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dfc39d",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b198c9c",
   "metadata": {},
   "source": [
    "In this section, we implemented a Neural Network model to capture complex patterns and interactions in the data that linear models might miss. Neural Networks are powerful models capable of learning non-linear relationships through multiple layers of interconnected neurons.\n",
    "\n",
    "**Steps Taken:**\n",
    "1. **Model Definition**: We defined a Sequential model with two Dense layers: one hidden layer with 100 neurons and a ReLU activation function, and an output layer with a sigmoid activation function.\n",
    "2. **Model Compilation**: The model was compiled using the Adam optimizer and binary cross-entropy loss, with accuracy as the evaluation metric.\n",
    "3. **Model Training**: The model was trained for 50 epochs with a batch size of 10, using the training data and validating on the test data.\n",
    "4. **Predictions**: Predictions were made on both the training and testing datasets, converting probabilities to binary outcomes.\n",
    "5. **Evaluation**: The model's performance was evaluated using accuracy on both training and test datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11afcffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the Neural Network model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Predicting on training and testing data\n",
    "y_train_pred_nn = (model.predict(X_train) > 0.5).astype(\"int32\")\n",
    "y_test_pred_nn = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculating Accuracy\n",
    "accuracy_train_nn = accuracy_score(y_train, y_train_pred_nn)\n",
    "accuracy_test_nn = accuracy_score(y_test, y_test_pred_nn)\n",
    "\n",
    "print(f\"Accuracy on Training Data: {accuracy_train_nn}\")\n",
    "print(f\"Accuracy on Test Data: {accuracy_test_nn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f70d6f",
   "metadata": {},
   "source": [
    "### Findings from Neural Network Model\n",
    "\n",
    "The Neural Network model was evaluated to determine its performance in predicting the target variable. The results are as follows:\n",
    "\n",
    "- **Accuracy on Training Data**: 0.9467\n",
    "- **Accuracy on Test Data**: 0.9454\n",
    "\n",
    "The high accuracy shows how well the neural network generalizes to new data and efficiently recognizes patterns in the training set. The neural network performs well, but its computing demands and complexity make it marginally less advantageous than the Random Forest model, which had the lowest Mean Squared Error (MSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eeb260",
   "metadata": {},
   "source": [
    "### Explanation for Choosing the Neural Network\n",
    "\n",
    "\n",
    "- **Ability to Capture Non-Linear Relationships**: Neural networks can model complex, non-linear interactions between features that simpler models might miss.\n",
    "- **Handling Large Datasets**: They are particularly effective for large datasets with multiple features.\n",
    "- **Flexible Architecture**: The flexibility in choosing the number of layers and neurons allows for fine-tuning the model to achieve optimal performance.\n",
    "- **High Accuracy**: Despite higher computational requirements, the neural network provided high accuracy on both training and test data.\n",
    "- **Adaptability**: Neural networks can adapt to a wide range of data types and distributions, making them versatile for different predictive tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
